APP_ENV=dev
APP_BASE_URL=http://localhost:8000

DB_PATH=/app/_local/data/app.db

# Provider defaults (start simple)

LLM_PROVIDER=openai
OPENAI_API_KEY=

# Embeddings defaults
# Provider: 'openai' (empfohlen) oder 'ollama' (lokal, kostenlos)
EMBEDDING_PROVIDER=openai

# OpenAI Modelle: text-embedding-3-small ($0.02/1M), text-embedding-3-large ($0.13/1M)
# Ollama Modelle: nomic-embed-text, mxbai-embed-large (kostenlos)
EMBEDDING_MODEL=text-embedding-3-small

# Ollama Server URL (nur relevant wenn EMBEDDING_PROVIDER=ollama)
# Im Docker: http://host.docker.internal:11434
# Lokal: http://localhost:11434
OLLAMA_BASE_URL=http://host.docker.internal:11434

# Guardrails / caps

DEFAULT_REQUIRE_CONFIRM_FOR_COSTLY_RUNS=1
MAX_LLM_CALLS_PER_DAY=50
MAX_EMBED_CALLS_PER_DAY=200

# Readwise Reader API (Token: https://readwise.io/access_token)

READWISE_API_TOKEN=

# Optional MCP key (only if required later)

CONTEXT7_API_KEY=
